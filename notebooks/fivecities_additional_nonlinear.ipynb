{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and classes\n",
    "\n",
    "import sys \n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "sys.path.append('..')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import packages\n",
    "from src.fivecities.experiment import run_experiment, plot_results_timehorizons, plot_results_PTS, model_dict_default\n",
    "from src.plotutils import print_table\n",
    "from src.fivecities.reader import FiveCities\n",
    "\n",
    "# Save images\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('../results/fivecities/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "#save_obj(results_dict, f'results_dict_{int(time.time())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results (if desired)\n",
    "def load_obj(name ):\n",
    "    with open('../results/fivecities/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "filename = None\n",
    "if filename:\n",
    "    results_dict = load_obj(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.baseline import RFRegressorLuPTS, KNRegressorLuPTS, ModelWrapper\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model_dict_extended = model_dict_default.copy()\n",
    "model_dict_extended['KNN'] = ModelWrapper(KNeighborsRegressor())\n",
    "model_dict_extended['RF'] = ModelWrapper(RandomForestRegressor())\n",
    "model_dict_extended['RF tuned'] = RFRegressorLuPTS()  # note, slows down experiment due to param tuning\n",
    "model_dict_extended['KNN tuned'] = KNRegressorLuPTS() # note, slows down experiment due to param tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments for prediction horizon of 6 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_list = [200]\n",
    "list_res = []\n",
    "for city in tqdm(FiveCities.city_list):\n",
    "    res = run_experiment(city, \n",
    "                        sequence_length = 5,\n",
    "                        timestep_list = [1],\n",
    "                        n_list = sample_size_list,\n",
    "                        model_dict=model_dict_extended)\n",
    "    list_res.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out tables for LaTeX\n",
    "for n_size in sample_size_list:\n",
    "    \n",
    "    print(f'Table for n={n_size}')\n",
    "    df = print_table(list_res, n_size=n_size, timestep=6)\n",
    "\n",
    "    filename = f'nonlinear_table_n{n_size}_h6_{int(time.time())}.csv'\n",
    "    df.to_csv('../results/fivecities/' + filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments for prediction horizon of 12 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_list = [200]\n",
    "list_res = []\n",
    "for city in tqdm(FiveCities.city_list):\n",
    "    res = run_experiment(city, \n",
    "                        sequence_length = 11,\n",
    "                        timestep_list = [6],\n",
    "                        n_list = sample_size_list,\n",
    "                        model_dict=model_dict_extended)\n",
    "    list_res.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out tables for LaTeX\n",
    "for n_size in sample_size_list:\n",
    "    \n",
    "    print(f'Table for n={n_size}')\n",
    "    df = print_table(list_res, n_size=n_size, timestep=6)\n",
    "\n",
    "    filename = f'nonlinear_table_n{n_size}_h12_{int(time.time())}.csv'\n",
    "    df.to_csv('../results/fivecities/' + filename)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "842f830ed209cc0244a6ead9f085f45cda77f2c864033aae5c6ee32e0c0ebcf3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ML': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
